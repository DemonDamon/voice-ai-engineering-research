AI能力现存问题
语音合成模型（TTS）适配

（一）并发问题
问题：华为910B卡主要适用于大语言模型的训练和推理。对于声学模型等小型模型，其底层支持不如英伟达的CUDA强大，导致无法通过主流推理加速框架VLLM进行服务化部署以实现性能的突破。目前适配效果仅支持单卡4路。
修改：我们选用cosyvoice2模型进行部署，并发的方案是多实例部署实现并发,6个worker共享一个910B卡，所以理论上单卡的并发是6路。(单卡间的服务分配使用triton实现，卡与卡间使用服务分配的负载均衡。) 根据和留言现有并发业务量，该配置下预计需要450张910B算卡，成本过高。

（二）推理效果问题
语音合成质量存在差距：910B卡在情感表达、清晰度和流畅度方面弱于英伟达卡存在差距。存在乱说话、切字断句不精准的问题。
修改：910B卡在情感表达、清晰度和流畅度方面弱于英伟达卡的推理结果。存在存在乱说话、杂音过多的问题。（目前初步排查为生成了大量的幻觉speech token）

全双工打断能力
（一）根据主声纹识别打断
目前没有好的技术方案。我们尝试了cam++等算法模型，分类主声纹效果不好。不	清楚是需要在工程化上优化还是在模型能力上优化。
算法模型的选型
声纹比对的工程化方案
（二）根据上下文理解打断
我们的方案是，在VAD识别语音活动的同时打断的基础上，加一个并行的大模型判断语义。当TTS在播放时，判断出用户说话内容并不是为了打断，TTS继续播报，否则打断。请教更好的打断方案。
 (三)   VAD参数设置方案
我们使用silero-vad模型。我们使用的置信度阈值和时间阈值分别是0.85和300ms。

语音识别能力
(一) 多语种识别
至今未提供测试报告，说明可支持多少种语种。
（三）多方言识别
至今未提供测试报告，说明可支持多少种语种
（四）并发问题 （资源成本过高） 
并发的方案是多实例部署实现并发，一个实例实现一个并发。ASR模型单实例占用1个vCPU资源。由于ASR模型服务不仅仅是部署ASR模型的，我们添加了一些前置（vad预切分）和后置处理（标点模型、ITN）的模块，所以需要的核数要大于能够支持的实例数。
（四）其他问题
	1、热词问题
我们的选用的模型是sensevoice，增加了一个热词的“插件”，但是加了热词之后会降低识别英文准确率。
2、识别准确率问题
模型是否添加热词的中文识别准确率都能在95%左右。这个是否有优化的空间。（测试方式，人工郎读已有文本，排除标点进行cer计算。）
   3、模型速度问题。
虽然sensevoice本身可以做到0.04的RTF，但是不支持流式识别，如果音频是10s这样的长音频，就需要400ms的首包。所以我们使用paraformer-online模型进行流式语音识别缩短时延，在200ms左右。
sensevoice 离线
paraformer-online 在线
paraformer-online 准确率 < sensevoice
有没有更好的模型

